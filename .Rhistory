Y = data$median_R_mean_we
}
# Return
return(list(data = data.frame(X = X, Y = Y, W = W)))
} # Data preparation half cantons
################################################################################
data = data.prep(lag = 7, shift = 14, response = "median_R_mean", r.infovar = 21, frequency = "weekly")$data
write.csv(data, "./Data/data_r_prep.csv")
data = data.prep(lag = 7, shift = 14, response = "casegrowth", r.infovar = 21, frequency = "weekly")$data
################################################################################
write.csv(data, "./Data/data_case_prep.csv")
data.prep = function(lag, shift, response, startdate = "2020-07-06",
enddate = "2020-12-21", r.infovar, frequency) {
# 2020-12-21
# lag: smoothing of covariates of lag days
# shift: shifting of response when using casegrowth as defined
# response: in {casegrowth, median_R_mean}
# startdate, enddate: to be adjusted for different time periods
# r.infovar: lag length of information variables
# frequency: in {daily, weekly}
# Output: data frame used for the estimation (Y, W, X)
# Note that the baseline mask policy of mandatory mask wearing was introduced nationally on "2020-07-06" and the
# first vaccinations took place on "2020-12-21". This is the reason for our sample selection.
# Read in data
DataCovid = read.csv(".\\Data\\DataCovid.csv")
dat.new = read.csv(".\\Data\\policy_stuff.csv", header = TRUE, sep = ",")
# Merge data on common days
data = merge(DataCovid, dat.new)
# Delete unnecessary variables to might lead to conflicts
data = data %>%
dplyr::select(-c(deaths_1d, recovered_1d, tests_1d, hosp_1d, value.total_1d, sre000d0_1d, tre200d0_1d, ure200d0_1d, O65P, restGatheringsCH)) %>%
rename(testingPolicy = testing_policyCH)
# Transform percentage to be a real percentage
data = data %>%
mutate(percentage_age = percentage_age*100)
# Get the daily date and weekly date as integer. Further construct disjoint weeks
data$day = cut.Date(as.Date(data$datum), breaks = "1 day", labels = FALSE)
data$oneweek = cut.Date(as.Date(data$datum), breaks = "1 week", start.on.monday = TRUE, labels = FALSE)
# Extract which value of oneweek corresponds to startdate, enddate to apply the time selection
# via the vector oneweek later
start.day = which(data$datum == startdate)[1]
start.week = data[start.day, "oneweek"]
end.day   = which(data$datum == enddate)[1]
end.week = data[end.day, "oneweek"]
if (response == "casegrowth" && frequency == "daily") {
# Construct target variable and lead target variable
data$casegrowth = dlogd(x = data$sumTotal, id = data$geoRegion, t = as.Date(data$datum), lag = lag)
data$casegrowth = panellag(x = data$casegrowth, i = data$geoRegion, t = as.Date(data$datum), lag = - shift)
# Apply the MA-operator to (X, W)
to.be.smoothed = c("grocery_and_pharmacy", "transit_stations", "Number.of.transactions", "workplaces",
"schoolClosing", "cancEvents", "restGatherings","testingPolicy", "workClosing2a",
"sre000d0", "tre200d0", "ure200d0", "mask_treat")
for (v in to.be.smoothed) {
data[,v] = panelma(x = data[,v], id = data$geoRegion, t = as.Date(data$datum), len = lag - 1)
}
# Lagged target variable
data$casegrowthlag = dlogd(x = data$sumTotal, id = data$geoRegion, t = as.Date(data$datum), lag = lag)
# log Delta Cit with Cit; new cases
data$logdiffcases = lognozero(paneldiff(x = data$sumTotal, id = data$geoRegion, t = as.Date(data$datum), lag = lag))
# Construct national aggregates
sumTotalCH = aggregate(data$sumTotal, by = list(data$datum), FUN  = sum)
sumTotalCH = rename(sumTotalCH, datum = Group.1)
sumTotalCH = rename(sumTotalCH, sumTotalCH = x)
data = merge(sumTotalCH, data)
data = data %>%
arrange(geoRegion)
# Lagged target variable on national level; works with id argument
data$casegrowthlag.national = dlogd(x = data$sumTotalCH, id = data$geoRegion, t = as.Date(data$datum), lag = lag)
# log Delta Cit; same as above but national level
data$logdiffcases.national = lognozero(paneldiff(x = data$sumTotalCH, id = data$geoRegion, t = as.Date(data$datum), lag = lag))
# Delta log T_it; already new tests so we do not have to apply the difference operator
data$difflogtests = dlogd(x = data$tests, id = data$geoRegion, t = as.Date(data$datum), lag = lag)
# Delta log transactions (one day rate)
data$Number.of.transactions[data$Number.of.transactions < 0.1] = 0.1
data$transactiongrowth = paneldiff(x = log(data$Number.of.transactions), id = data$geoRegion, t = as.Date(data$datum), lag = 1)
# Correct period
data = data %>%
filter(datum >= startdate & datum <= enddate)
# Change the ordering of cantons to adjust for the ordering of the adjacency matrix: we work with Canton_3 as the
# cantonal indicator later so we order the data along the list target where we input the ordering of the adjacency matrix
# used later so the data is ordered.
target = c(2, 4, 5, 11, 3, 9, 17, 16, 22, 24, 20, 12, 8, 10, 6, 1, 15, 13, 14, 23, 18, 26, 21, 19, 7, 25)
data = data %>%
slice(order(factor(Canton_3, levels = target)))
# Construct X daily
X = data[,c("casegrowthlag", "logdiffcases", "casegrowthlag.national", "logdiffcases.national", "difflogtests",
"percentage_age", "Density", "population",
"schoolClosing", "restGatherings", "cancEvents",
"testingPolicy", "workClosing2a",
"grocery_and_pharmacy", "transit_stations", "transactiongrowth", "workplaces",
"sre000d0", "tre200d0", "ure200d0", "ferien", "Canton_3", "day")]
W = data$mask_treat
Y = data$casegrowth
}
if (response == "casegrowth" && frequency == "weekly") {
# Construct target variable and lagged target variable. We do that by computing the new cases per canton and week. We can then
# compute the log-growth rate using that series, which constructs 7 times that same growth rate per canton and week. When aggregating,
# we can then take the mean over disjoint weeks to obtain the desired variable. We do that for all growth rates.
# Construct national aggregates
sumTotalCH = aggregate(data$sumTotal, by = list(data$datum), FUN  = sum)
sumTotalCH = rename(sumTotalCH, datum = Group.1)
sumTotalCH = rename(sumTotalCH, sumTotalCH = x)
data = merge(sumTotalCH, data)
data = data %>%
arrange(geoRegion)
# Get new cases per day in each canton. Do it for the new cases on a national level as well.
data = data %>%
group_by(geoRegion) %>%
mutate(NewCases = c(0,diff(sumTotal)),
NewCases.national = c(0, diff(sumTotalCH))) %>%
ungroup()
data = data %>%
relocate(sumTotal, .before = NewCases)
# We now have all variables constant across oneweek and canton which need to be constant. The other ones
# are aggregated to weekly data by simply averaging the values per week and canton. Note that we take the sum
# for transactions and tests as we need the new number of transactions and tests per canton and week. These variables
# already come supplied as new transactions and tests so we do not have to treat them as the cases where we had to explicitely
# calculate the new cases as done in the above code.
data = data %>%
group_by(Canton_3, oneweek) %>%
summarize(newcases_we           = sum(NewCases),
newcases.national_we  = sum(NewCases.national),
newtransactions_we    = sum(Number.of.transactions),
newtests_we           = sum(tests),
percentage_age_we = mean(percentage_age),
Density_we        = mean(Density),
population_we     = mean(population),
grocery_and_pharmacy_we   = mean(grocery_and_pharmacy),
transit_stations_we       = mean(transit_stations),
workplaces_we             = mean(workplaces),
ferien_we                 = mean(ferien),
sre000d0_we               = mean(sre000d0),
tre200d0_we               = mean(tre200d0),
ure200d0_we               = mean(ure200d0),
schoolClosing_we          = mean(schoolClosing),
restGatherings_we         = mean(restGatherings),
cancEvents_we             = mean(cancEvents),
testingPolicy_we          = mean(testingPolicy),
workClosing2a_we          = mean(workClosing2a),
mask_treat_we             = mean(mask_treat)) %>%
ungroup()
# Using newcases_we, newcases.national_we, newtransactions_we and newtests_we, we can now compute the weekly growth rates.
# Create the response variable and lead response variable.
# Check if values are below the threshold of 0.1 and set it to 0.1 if so. Does not happen
data$newcases_we[data$newcases_we < 0.1] = 0.1
data$casegrowth_we = paneldiff(x = log(data$newcases_we), id = data$Canton_3, t = as.Date(data$oneweek), l = 1)
data$casegrowth_we = panellag(x = data$casegrowth_we, i = data$Canton_3, t = as.Date(data$oneweek), lag = -shift/7)
# Lagged target variable
data$casegrowthlag_we =  panellag(x = data$casegrowth_we, i = data$Canton_3, t = data$oneweek, lag = 2)
data$casegrowthlag1_we = panellag(x = data$casegrowth_we, i = data$Canton_3, t = data$oneweek, lag = 1)
# log Delta Cit
data$logdiffcases_we = lognozero(paneldiff(x = data$newcases_we, id = data$Canton_3, t = as.Date(data$oneweek), lag = 1))
# Lagged target variable on national level; works with id argument
data$newcases.national_we[data$newcases.national_we < 0.1] = 0.1
data$casegrowthlag.national_we = paneldiff(x = log(data$newcases.national_we), id = data$Canton_3, t = as.Date(data$oneweek), l = 1)
# log Delta Cit; same as above but national level
data$logdiffcases.national_we = lognozero(paneldiff(x = data$newcases.national_we, id = data$Canton_3, t = as.Date(data$oneweek), lag = 1))
# Delta log Tit; already new tests so we do not have to apply the difference operator
data$newtests_we[data$newtests_we < 0.1] = 0.1
data$difflogtests_we = paneldiff(x = log(data$newtests_we), id = data$Canton_3, t = as.Date(data$oneweek), l = 1)
# Delta log transactions
data$newtransactions_we[data$newtransactions_we < 0.1] = 0.1
data$transactiongrowth_we = paneldiff(x = log(data$newtransactions_we), id = data$Canton_3, t = as.Date(data$oneweek), l = 1)
# Correct period
data = data %>%
filter(oneweek >= start.week & oneweek <= end.week)
# Change the ordering of cantons to adjust for the ordering of the adjacency matrix: we work with Canton_3 as the
# cantonal indicator later so we order the data along the list target where we input the ordering of the adjacency matrix
# used later so the data is ordered.
target = c(2, 4, 5, 11, 3, 9, 17, 16, 22, 24, 20, 12, 8, 10, 6, 1, 15, 13, 14, 23, 18, 26, 21, 19, 7, 25)
data = data %>%
slice(order(factor(Canton_3, levels = target)))
# Construct X weekly
X = data[,c("casegrowthlag_we", "casegrowthlag1_we", "logdiffcases_we", "casegrowthlag.national_we", "logdiffcases.national_we", "difflogtests_we",
"percentage_age_we", "Density_we", "population_we",
"schoolClosing_we", "restGatherings_we", "cancEvents_we",
"testingPolicy_we", "workClosing2a_we",
"grocery_and_pharmacy_we", "transit_stations_we", "transactiongrowth_we", "workplaces_we",
"sre000d0_we", "tre200d0_we", "ure200d0_we", "ferien_we", "Canton_3", "oneweek")]
W = data$mask_treat_we
Y = data$casegrowth_we
}
if (response == "median_R_mean" && frequency == "daily") {
# lagged target variable
data$median_R_mean.lag = panellag(x = data$median_R_mean, i = data$geoRegion, t = as.Date(data$datum), lag = r.infovar)
#data$median_R_mean.lag1 = panellag(x = data$median_R_mean, i = data$geoRegion, t = as.Date(data$datum), lag = 7)
# Delta log transactions (one day rate)
data$Number.of.transactions[data$Number.of.transactions < 0.1] = 0.1
data$transactiongrowth = paneldiff(x = log(data$Number.of.transactions), id = data$geoRegion, t = as.Date(data$datum), lag = 1)
# Correct period
data = data %>%
filter(datum >= startdate & datum <= enddate)
# Change the ordering of cantons to adjust for the ordering of the adjacency matrix: we work with Canton_3 as the
# cantonal indicator later so we order the data along the list target where we input the ordering of the adjacency matrix
# used later so the data is ordered.
target = c(2, 4, 5, 11, 3, 9, 17, 16, 22, 24, 20, 12, 8, 10, 6, 1, 15, 13, 14, 23, 18, 26, 21, 19, 7, 25)
data = data %>%
slice(order(factor(Canton_3, levels = target)))
# Construct X daily
X = data[,c("median_R_mean.lag",
"percentage_age", "Density", "population",
"schoolClosing", "restGatherings", "cancEvents",
"testingPolicy", "workClosing2a",
"grocery_and_pharmacy", "transit_stations", "transactiongrowth", "workplaces",
"sre000d0", "tre200d0", "ure200d0", "ferien", "Canton_3", "day")]
W = data$mask_treat
Y = data$median_R_mean
}
if (response == "median_R_mean" && frequency == "weekly") {
# Take the mean over the disjoint weeks for (Y,W,X)
data = data %>%
group_by(Canton_3, oneweek) %>%
summarize(median_R_mean_we      = mean(median_R_mean),
percentage_age_we = mean(percentage_age),
Density_we        = mean(Density),
population_we     = mean(population),
grocery_and_pharmacy_we   = mean(grocery_and_pharmacy),
transit_stations_we       = mean(transit_stations),
newtransactions_we        = sum(Number.of.transactions),
workplaces_we             = mean(workplaces),
ferien_we                 = mean(ferien),
sre000d0_we               = mean(sre000d0),
tre200d0_we               = mean(tre200d0),
ure200d0_we               = mean(ure200d0),
schoolClosing_we          = mean(schoolClosing),
restGatherings_we         = mean(restGatherings),
cancEvents_we             = mean(cancEvents),
testingPolicy_we          = mean(testingPolicy),
workClosing2a_we          = mean(workClosing2a),
mask_treat_we             = mean(mask_treat)) %>%
ungroup()
# Delta log transactions
data$newtransactions_we[data$newtransactions_we < 0.1] = 0.1
data$transactiongrowth_we = paneldiff(x = log(data$newtransactions_we), id = data$Canton_3, t = as.Date(data$oneweek), l = 1)
# Lagged target variable
data$median_R_mean.lag_we = panellag(x = data$median_R_mean_we, i = data$Canton_3, t = data$oneweek, lag = r.infovar/7)
data$median_R_mean.lag1_we = panellag(x = data$median_R_mean_we, i = data$Canton_3, t = data$oneweek, lag = 1)
# Correct period
data = data %>%
filter(oneweek >= start.week & oneweek <= end.week)
# Change the ordering of cantons to adjust for the ordering of the adjacency matrix: we work with Canton_3 as the
# cantonal indicator later so we order the data along the list target where we input the ordering of the adjacency matrix
# used later so the data is ordered.
target = c(2, 4, 5, 11, 3, 9, 17, 16, 22, 24, 20, 12, 8, 10, 6, 1, 15, 13, 14, 23, 18, 26, 21, 19, 7, 25)
data = data %>%
slice(order(factor(Canton_3, levels = target)))
# Construct X weekly
X = data[,c("median_R_mean.lag_we", "median_R_mean.lag1_we",
"percentage_age_we", "Density_we", "population_we",
"schoolClosing_we", "restGatherings_we", "cancEvents_we",
"testingPolicy_we", "workClosing2a_we",
"grocery_and_pharmacy_we", "transit_stations_we", "transactiongrowth_we", "workplaces_we",
"sre000d0_we", "tre200d0_we", "ure200d0_we", "ferien_we", "Canton_3", "oneweek")]
W = data$mask_treat_we
Y = data$median_R_mean_we
}
# Return
return(list(data = data.frame(X = X, Y = Y, W = W)))
} # Data preparation
data = data.prep(lag = 7, shift = 14, response = "casegrowth", r.infovar = 21, frequency = "weekly")$data
View(data)
unique(data$X.schoolClosing_we)
data.prep = function(lag, shift, response, startdate = "2020-07-06",
enddate = "2020-10-18", r.infovar, frequency) {
# 2020-12-21
# lag: smoothing of covariates of lag days
# shift: shifting of response when using casegrowth as defined
# response: in {casegrowth, median_R_mean}
# startdate, enddate: to be adjusted for different time periods
# r.infovar: lag length of information variables
# frequency: in {daily, weekly}
# Output: data frame used for the estimation (Y, W, X)
# Note that the baseline mask policy of mandatory mask wearing was introduced nationally on "2020-07-06" and the
# first vaccinations took place on "2020-12-21". This is the reason for our sample selection.
# Read in data
DataCovid = read.csv(".\\Data\\DataCovid.csv")
dat.new = read.csv(".\\Data\\policy_stuff.csv", header = TRUE, sep = ",")
# Merge data on common days
data = merge(DataCovid, dat.new)
# Delete unnecessary variables to might lead to conflicts
data = data %>%
dplyr::select(-c(deaths_1d, recovered_1d, tests_1d, hosp_1d, value.total_1d, sre000d0_1d, tre200d0_1d, ure200d0_1d, O65P, restGatheringsCH)) %>%
rename(testingPolicy = testing_policyCH)
# Transform percentage to be a real percentage
data = data %>%
mutate(percentage_age = percentage_age*100)
# Get the daily date and weekly date as integer. Further construct disjoint weeks
data$day = cut.Date(as.Date(data$datum), breaks = "1 day", labels = FALSE)
data$oneweek = cut.Date(as.Date(data$datum), breaks = "1 week", start.on.monday = TRUE, labels = FALSE)
# Extract which value of oneweek corresponds to startdate, enddate to apply the time selection
# via the vector oneweek later
start.day = which(data$datum == startdate)[1]
start.week = data[start.day, "oneweek"]
end.day   = which(data$datum == enddate)[1]
end.week = data[end.day, "oneweek"]
if (response == "casegrowth" && frequency == "daily") {
# Construct target variable and lead target variable
data$casegrowth = dlogd(x = data$sumTotal, id = data$geoRegion, t = as.Date(data$datum), lag = lag)
data$casegrowth = panellag(x = data$casegrowth, i = data$geoRegion, t = as.Date(data$datum), lag = - shift)
# Apply the MA-operator to (X, W)
to.be.smoothed = c("grocery_and_pharmacy", "transit_stations", "Number.of.transactions", "workplaces",
"schoolClosing", "cancEvents", "restGatherings","testingPolicy", "workClosing2a",
"sre000d0", "tre200d0", "ure200d0", "mask_treat")
for (v in to.be.smoothed) {
data[,v] = panelma(x = data[,v], id = data$geoRegion, t = as.Date(data$datum), len = lag - 1)
}
# Lagged target variable
data$casegrowthlag = dlogd(x = data$sumTotal, id = data$geoRegion, t = as.Date(data$datum), lag = lag)
# log Delta Cit with Cit; new cases
data$logdiffcases = lognozero(paneldiff(x = data$sumTotal, id = data$geoRegion, t = as.Date(data$datum), lag = lag))
# Construct national aggregates
sumTotalCH = aggregate(data$sumTotal, by = list(data$datum), FUN  = sum)
sumTotalCH = rename(sumTotalCH, datum = Group.1)
sumTotalCH = rename(sumTotalCH, sumTotalCH = x)
data = merge(sumTotalCH, data)
data = data %>%
arrange(geoRegion)
# Lagged target variable on national level; works with id argument
data$casegrowthlag.national = dlogd(x = data$sumTotalCH, id = data$geoRegion, t = as.Date(data$datum), lag = lag)
# log Delta Cit; same as above but national level
data$logdiffcases.national = lognozero(paneldiff(x = data$sumTotalCH, id = data$geoRegion, t = as.Date(data$datum), lag = lag))
# Delta log T_it; already new tests so we do not have to apply the difference operator
data$difflogtests = dlogd(x = data$tests, id = data$geoRegion, t = as.Date(data$datum), lag = lag)
# Delta log transactions (one day rate)
data$Number.of.transactions[data$Number.of.transactions < 0.1] = 0.1
data$transactiongrowth = paneldiff(x = log(data$Number.of.transactions), id = data$geoRegion, t = as.Date(data$datum), lag = 1)
# Correct period
data = data %>%
filter(datum >= startdate & datum <= enddate)
# Change the ordering of cantons to adjust for the ordering of the adjacency matrix: we work with Canton_3 as the
# cantonal indicator later so we order the data along the list target where we input the ordering of the adjacency matrix
# used later so the data is ordered.
target = c(2, 4, 5, 11, 3, 9, 17, 16, 22, 24, 20, 12, 8, 10, 6, 1, 15, 13, 14, 23, 18, 26, 21, 19, 7, 25)
data = data %>%
slice(order(factor(Canton_3, levels = target)))
# Construct X daily
X = data[,c("casegrowthlag", "logdiffcases", "casegrowthlag.national", "logdiffcases.national", "difflogtests",
"percentage_age", "Density", "population",
"schoolClosing", "restGatherings", "cancEvents",
"testingPolicy", "workClosing2a",
"grocery_and_pharmacy", "transit_stations", "transactiongrowth", "workplaces",
"sre000d0", "tre200d0", "ure200d0", "ferien", "Canton_3", "day")]
W = data$mask_treat
Y = data$casegrowth
}
if (response == "casegrowth" && frequency == "weekly") {
# Construct target variable and lagged target variable. We do that by computing the new cases per canton and week. We can then
# compute the log-growth rate using that series, which constructs 7 times that same growth rate per canton and week. When aggregating,
# we can then take the mean over disjoint weeks to obtain the desired variable. We do that for all growth rates.
# Construct national aggregates
sumTotalCH = aggregate(data$sumTotal, by = list(data$datum), FUN  = sum)
sumTotalCH = rename(sumTotalCH, datum = Group.1)
sumTotalCH = rename(sumTotalCH, sumTotalCH = x)
data = merge(sumTotalCH, data)
data = data %>%
arrange(geoRegion)
# Get new cases per day in each canton. Do it for the new cases on a national level as well.
data = data %>%
group_by(geoRegion) %>%
mutate(NewCases = c(0,diff(sumTotal)),
NewCases.national = c(0, diff(sumTotalCH))) %>%
ungroup()
data = data %>%
relocate(sumTotal, .before = NewCases)
# We now have all variables constant across oneweek and canton which need to be constant. The other ones
# are aggregated to weekly data by simply averaging the values per week and canton. Note that we take the sum
# for transactions and tests as we need the new number of transactions and tests per canton and week. These variables
# already come supplied as new transactions and tests so we do not have to treat them as the cases where we had to explicitely
# calculate the new cases as done in the above code.
data = data %>%
group_by(Canton_3, oneweek) %>%
summarize(newcases_we           = sum(NewCases),
newcases.national_we  = sum(NewCases.national),
newtransactions_we    = sum(Number.of.transactions),
newtests_we           = sum(tests),
percentage_age_we = mean(percentage_age),
Density_we        = mean(Density),
population_we     = mean(population),
grocery_and_pharmacy_we   = mean(grocery_and_pharmacy),
transit_stations_we       = mean(transit_stations),
workplaces_we             = mean(workplaces),
ferien_we                 = mean(ferien),
sre000d0_we               = mean(sre000d0),
tre200d0_we               = mean(tre200d0),
ure200d0_we               = mean(ure200d0),
schoolClosing_we          = mean(schoolClosing),
restGatherings_we         = mean(restGatherings),
cancEvents_we             = mean(cancEvents),
testingPolicy_we          = mean(testingPolicy),
workClosing2a_we          = mean(workClosing2a),
mask_treat_we             = mean(mask_treat)) %>%
ungroup()
# Using newcases_we, newcases.national_we, newtransactions_we and newtests_we, we can now compute the weekly growth rates.
# Create the response variable and lead response variable.
# Check if values are below the threshold of 0.1 and set it to 0.1 if so. Does not happen
data$newcases_we[data$newcases_we < 0.1] = 0.1
data$casegrowth_we = paneldiff(x = log(data$newcases_we), id = data$Canton_3, t = as.Date(data$oneweek), l = 1)
data$casegrowth_we = panellag(x = data$casegrowth_we, i = data$Canton_3, t = as.Date(data$oneweek), lag = -shift/7)
# Lagged target variable
data$casegrowthlag_we =  panellag(x = data$casegrowth_we, i = data$Canton_3, t = data$oneweek, lag = 2)
data$casegrowthlag1_we = panellag(x = data$casegrowth_we, i = data$Canton_3, t = data$oneweek, lag = 1)
# log Delta Cit
data$logdiffcases_we = lognozero(paneldiff(x = data$newcases_we, id = data$Canton_3, t = as.Date(data$oneweek), lag = 1))
# Lagged target variable on national level; works with id argument
data$newcases.national_we[data$newcases.national_we < 0.1] = 0.1
data$casegrowthlag.national_we = paneldiff(x = log(data$newcases.national_we), id = data$Canton_3, t = as.Date(data$oneweek), l = 1)
# log Delta Cit; same as above but national level
data$logdiffcases.national_we = lognozero(paneldiff(x = data$newcases.national_we, id = data$Canton_3, t = as.Date(data$oneweek), lag = 1))
# Delta log Tit; already new tests so we do not have to apply the difference operator
data$newtests_we[data$newtests_we < 0.1] = 0.1
data$difflogtests_we = paneldiff(x = log(data$newtests_we), id = data$Canton_3, t = as.Date(data$oneweek), l = 1)
# Delta log transactions
data$newtransactions_we[data$newtransactions_we < 0.1] = 0.1
data$transactiongrowth_we = paneldiff(x = log(data$newtransactions_we), id = data$Canton_3, t = as.Date(data$oneweek), l = 1)
# Correct period
data = data %>%
filter(oneweek >= start.week & oneweek <= end.week)
# Change the ordering of cantons to adjust for the ordering of the adjacency matrix: we work with Canton_3 as the
# cantonal indicator later so we order the data along the list target where we input the ordering of the adjacency matrix
# used later so the data is ordered.
target = c(2, 4, 5, 11, 3, 9, 17, 16, 22, 24, 20, 12, 8, 10, 6, 1, 15, 13, 14, 23, 18, 26, 21, 19, 7, 25)
data = data %>%
slice(order(factor(Canton_3, levels = target)))
# Construct X weekly
X = data[,c("casegrowthlag_we", "casegrowthlag1_we", "logdiffcases_we", "casegrowthlag.national_we", "logdiffcases.national_we", "difflogtests_we",
"percentage_age_we", "Density_we", "population_we",
"schoolClosing_we", "restGatherings_we", "cancEvents_we",
"testingPolicy_we", "workClosing2a_we",
"grocery_and_pharmacy_we", "transit_stations_we", "transactiongrowth_we", "workplaces_we",
"sre000d0_we", "tre200d0_we", "ure200d0_we", "ferien_we", "Canton_3", "oneweek")]
W = data$mask_treat_we
Y = data$casegrowth_we
}
if (response == "median_R_mean" && frequency == "daily") {
# lagged target variable
data$median_R_mean.lag = panellag(x = data$median_R_mean, i = data$geoRegion, t = as.Date(data$datum), lag = r.infovar)
#data$median_R_mean.lag1 = panellag(x = data$median_R_mean, i = data$geoRegion, t = as.Date(data$datum), lag = 7)
# Delta log transactions (one day rate)
data$Number.of.transactions[data$Number.of.transactions < 0.1] = 0.1
data$transactiongrowth = paneldiff(x = log(data$Number.of.transactions), id = data$geoRegion, t = as.Date(data$datum), lag = 1)
# Correct period
data = data %>%
filter(datum >= startdate & datum <= enddate)
# Change the ordering of cantons to adjust for the ordering of the adjacency matrix: we work with Canton_3 as the
# cantonal indicator later so we order the data along the list target where we input the ordering of the adjacency matrix
# used later so the data is ordered.
target = c(2, 4, 5, 11, 3, 9, 17, 16, 22, 24, 20, 12, 8, 10, 6, 1, 15, 13, 14, 23, 18, 26, 21, 19, 7, 25)
data = data %>%
slice(order(factor(Canton_3, levels = target)))
# Construct X daily
X = data[,c("median_R_mean.lag",
"percentage_age", "Density", "population",
"schoolClosing", "restGatherings", "cancEvents",
"testingPolicy", "workClosing2a",
"grocery_and_pharmacy", "transit_stations", "transactiongrowth", "workplaces",
"sre000d0", "tre200d0", "ure200d0", "ferien", "Canton_3", "day")]
W = data$mask_treat
Y = data$median_R_mean
}
if (response == "median_R_mean" && frequency == "weekly") {
# Take the mean over the disjoint weeks for (Y,W,X)
data = data %>%
group_by(Canton_3, oneweek) %>%
summarize(median_R_mean_we      = mean(median_R_mean),
percentage_age_we = mean(percentage_age),
Density_we        = mean(Density),
population_we     = mean(population),
grocery_and_pharmacy_we   = mean(grocery_and_pharmacy),
transit_stations_we       = mean(transit_stations),
newtransactions_we        = sum(Number.of.transactions),
workplaces_we             = mean(workplaces),
ferien_we                 = mean(ferien),
sre000d0_we               = mean(sre000d0),
tre200d0_we               = mean(tre200d0),
ure200d0_we               = mean(ure200d0),
schoolClosing_we          = mean(schoolClosing),
restGatherings_we         = mean(restGatherings),
cancEvents_we             = mean(cancEvents),
testingPolicy_we          = mean(testingPolicy),
workClosing2a_we          = mean(workClosing2a),
mask_treat_we             = mean(mask_treat)) %>%
ungroup()
# Delta log transactions
data$newtransactions_we[data$newtransactions_we < 0.1] = 0.1
data$transactiongrowth_we = paneldiff(x = log(data$newtransactions_we), id = data$Canton_3, t = as.Date(data$oneweek), l = 1)
# Lagged target variable
data$median_R_mean.lag_we = panellag(x = data$median_R_mean_we, i = data$Canton_3, t = data$oneweek, lag = r.infovar/7)
data$median_R_mean.lag1_we = panellag(x = data$median_R_mean_we, i = data$Canton_3, t = data$oneweek, lag = 1)
# Correct period
data = data %>%
filter(oneweek >= start.week & oneweek <= end.week)
# Change the ordering of cantons to adjust for the ordering of the adjacency matrix: we work with Canton_3 as the
# cantonal indicator later so we order the data along the list target where we input the ordering of the adjacency matrix
# used later so the data is ordered.
target = c(2, 4, 5, 11, 3, 9, 17, 16, 22, 24, 20, 12, 8, 10, 6, 1, 15, 13, 14, 23, 18, 26, 21, 19, 7, 25)
data = data %>%
slice(order(factor(Canton_3, levels = target)))
# Construct X weekly
X = data[,c("median_R_mean.lag_we", "median_R_mean.lag1_we",
"percentage_age_we", "Density_we", "population_we",
"schoolClosing_we", "restGatherings_we", "cancEvents_we",
"testingPolicy_we", "workClosing2a_we",
"grocery_and_pharmacy_we", "transit_stations_we", "transactiongrowth_we", "workplaces_we",
"sre000d0_we", "tre200d0_we", "ure200d0_we", "ferien_we", "Canton_3", "oneweek")]
W = data$mask_treat_we
Y = data$median_R_mean_we
}
# Return
return(list(data = data.frame(X = X, Y = Y, W = W)))
} # Data preparation
data = data.prep(lag = 7, shift = 14, response = "casegrowth", r.infovar = 21, frequency = "weekly")$data
unique(data$X.schoolClosing_we)
