results.infovar[j,3] = estimation(frequency = frequency, response = response, model = model, infovar = infovar, type.effect = type.effect)$results[[1]]["W",4]
j = j + 1
}
# Naming
results.infovar = as.data.frame(results.infovar, row.names = c("Add. Infovars RE Casegrowth direct", "Add. Infovars RE Casegrowth total"))
View(results.infovar)
conf_int(-0.1823312
, 0.1012853, 390 - 12)
(3) Merge the half cantons of Switzerland together as one can argue that they do not constitute separate observations due to
# Result matrix
results.halfcanton = matrix(NA, nrow = 4, ncol = 3)
colnames(results.halfcanton) = c("estimate", "std.error", "p.val")
# Parameters
resp.poss = c("casegrowth", "median_R_mean")
model.poss = c("within", "random")
type.effect = "total"
frequency = "weekly"
infovar = FALSE
# Allocation
j = 1
# Run the models
for (model in model.poss) {
for (response in resp.poss) {
# Store formula
formula = construct.formula(response = response, frequency = frequency, model = model, infovar = infovar, type.effect = type.effect)
# Store data; change configuration of data processing here to examine lag, shift and r.infovar
data = data.prep.halfcantons(shift = 14, response = response, r.infovar = 21)$data
# Models
fit = plm(formula,
data = data, model = model,
index = c("X.Canton_3", "X.oneweek"),
effect = "twoways")
if (model == "within") {
# Covariance matrix
res = coeftest(fit, vcov = function(x)
clubSandwich::vcovCR(x, type = "CR0", cluster = c(data$X.oneweek, data$X.Canton_3)))
# Results
results.halfcanton[j,1] = res["W",1]
results.halfcanton[j,2] = res["W",2]
results.halfcanton[j,3] = res["W",4]
} else {
# Covariance matrix
res = coeftest(fit, vcov = function(x)
plm::vcovHC(x, method = "white1", type = "HC3"))
# Results
results.halfcanton[j,1] = res["W",1]
results.halfcanton[j,2] = res["W",2]
results.halfcanton[j,3] = res["W",4]
}
j = j + 1
}
}
# Naming
results.halfcanton = as.data.frame(results.halfcanton, row.names = c("Halfcant. FE Casegrowth", "Halfcant. FE R", "Halfcant. RE Casegrowth",
"Halfcant. RE R"))
View(results.halfcanton)
conf_int(results.halfcanton[1,1], results.halfcanton[1,2])
24*15
conf_int(results.halfcanton[1,1], results.halfcanton[1,2] df = 360-12)
conf_int(results.halfcanton[1,1], results.halfcanton[1,2], df = 360-12)
conf_int(results.halfcanton[2,1], results.halfcanton[2,2], df = 360-12)
conf_int(results.halfcanton[4,1], results.halfcanton[4,2], df = 360-12)
conf_int(results.halfcanton[3,1], results.halfcanton[3,2], df = 360-12)
# Half-cantons for DFE
multiple_split_half = function(response, frequency, infovar, type.effect) {
# response: response variable in {median_R_mean, casegrowth}
# frequency: frequency in {daily, weekly}
# infovar: add additional information variables
# type.effect: direct or total to include behavior variables or not
# Output: bias.corrected estimate of mask policy
# Data
data = data.prep.halfcantons(response = response, r.infovar = 21, shift = 14)$data
# Store formula
formula = construct.formula(response = response, frequency = frequency, model = "within", infovar = infovar, type.effect = type.effect)
# Number of splits along the cross-section
s = 20
# Fit non-debiased model daily or weekly and save time and unit for sampling later
if (frequency == "daily") {
uc     = plm(formula, data = data, model = "within", index = c("X.Canton_3", "X.day"), effect = "twoways")
time   = as.double(data$X.day)
unit   = as.double(data$X.Canton_3)
} else {
uc     = plm(formula, data = data, model = "within", index = c("X.Canton_3", "X.oneweek"), effect = "twoways")
time   = as.double(data$X.oneweek)
unit   = as.double(data$X.Canton_3)
}
# Start computation
across = 0 * coef(uc)
for (k in 1:s) {
# Sampling process
sample1 = sample(unique(unit), ceiling(length(unique(unit))/2), replace = FALSE)
subsample1 = ((unit %in% sample1) & (time <= median(time))) |
((!(unit %in% sample1)) & (time > median(time)))
subsample2 = ((unit %in% sample1) & (time > median(time))) |
((!(unit %in% sample1)) & (time <= median(time)))
if (frequency == "daily") {
cross1 = plm(formula, data = data[subsample1,], model = "within",
index = c("X.Canton_3", "X.day"), effect = "twoways")
cross2 = plm(formula, data = data[subsample2,], model = "within",
index = c("X.Canton_3", "X.day"),effect = "twoways")
} else {
cross1 = plm(formula, data = data[subsample1,], model = "within",
index = c("X.Canton_3", "X.oneweek"), effect = "twoways")
cross2 = plm(formula, data = data[subsample2,], model = "within",
index = c("X.Canton_3", "X.oneweek"),effect = "twoways")
}
across = across + ((coef(cross1) + coef(cross2))/2)/s
}
# Average cross over corrected
acbc = 2 * coef(uc) - across
return(acbc)
}
# Run it for the DFE approach
multiple_split_half(response = "median_R_mean", frequency = "weekly", infovar = FALSE, type.effect = "total")
View(results.halfcanton)
conf_int(-0.2111976467, 0.05675987, 360-12)
multiple_split_half(response = "casegrowth", frequency = "weekly", infovar = FALSE, type.effect = "total")
conf_int(-0.3476905272, 0.11203383, 360-12)
results.rinfovar = matrix(NA, nrow = 2, ncol = 3)
colnames(results.rinfovar) = c("estimate", "std.error", "p.val")
# Parameters
model.poss = c("within", "random")
response = "median_R_mean"
frequency = "weekly"
type.effect = "total"
infovar = FALSE
# Allocation
j = 1
# Run the models
for (model in model.poss) {
# Store formula
formula = construct.formula(response = response, frequency = frequency, model = model, infovar = infovar, type.effect = type.effect)
# Store data; change configuration of data processing here to examine lag, shift and r.infovar
data = data.prep(lag = 7, shift = 14, response = response, r.infovar = 14, frequency = frequency)$data
# Models
fit = plm(formula,
data = data, model = model,
index = c("X.Canton_3", "X.oneweek"),
effect = "twoways")
if (model == "within") {
# Covariance matrix
res = coeftest(fit, vcov = function(x)
clubSandwich::vcovCR(x, type = "CR0", cluster = c(data$X.oneweek, data$X.Canton_3)))
# Results
results.rinfovar[j,1] = res["W",1]
results.rinfovar[j,2] = res["W",2]
results.rinfovar[j,3] = res["W",4]
} else {
# Covariance matrix
res = coeftest(fit, vcov = function(x)
sandwich::vcovHC(x, type = "HC3"))
# Results
results.rinfovar[j,1] = res["W",1]
results.rinfovar[j,2] = res["W",2]
results.rinfovar[j,3] = res["W",4]
}
j = j + 1
}
# Naming
results.rinfovar = as.data.frame(results.rinfovar, row.names = c("R-Infovar 14 FE R", "R-Infovar 14 RE R"))
View(results.infovar)
conf_int(-0.1823312, 0.1012853, df = 390-15)
View(results.infovar)
results.rinfovar = matrix(NA, nrow = 2, ncol = 3)
colnames(results.rinfovar) = c("estimate", "std.error", "p.val")
# Parameters
model.poss = c("within", "random")
response = "median_R_mean"
frequency = "weekly"
type.effect = "total"
infovar = FALSE
# Allocation
j = 1
# Run the models
for (model in model.poss) {
# Store formula
formula = construct.formula(response = response, frequency = frequency, model = model, infovar = infovar, type.effect = type.effect)
# Store data; change configuration of data processing here to examine lag, shift and r.infovar
data = data.prep(lag = 7, shift = 14, response = response, r.infovar = 14, frequency = frequency)$data
# Models
fit = plm(formula,
data = data, model = model,
index = c("X.Canton_3", "X.oneweek"),
effect = "twoways")
if (model == "within") {
# Covariance matrix
res = coeftest(fit, vcov = function(x)
clubSandwich::vcovCR(x, type = "CR0", cluster = c(data$X.oneweek, data$X.Canton_3)))
# Results
results.rinfovar[j,1] = res["W",1]
results.rinfovar[j,2] = res["W",2]
results.rinfovar[j,3] = res["W",4]
} else {
# Covariance matrix
res = coeftest(fit, vcov = function(x)
sandwich::vcovHC(x, type = "HC3"))
# Results
results.rinfovar[j,1] = res["W",1]
results.rinfovar[j,2] = res["W",2]
results.rinfovar[j,3] = res["W",4]
}
j = j + 1
}
# Naming
results.rinfovar = as.data.frame(results.rinfovar, row.names = c("R-Infovar 14 FE R", "R-Infovar 14 RE R"))
View(results.infovar)
# Naming
results.rinfovar = as.data.frame(results.rinfovar, row.names = c("R-Infovar 14 FE R", "R-Infovar 14 RE R"))
View(results.rinfovar)
conf_int(-0.1649698
, 0.04425725, df = 390-15)
conf_int(-0.1649698
, 0.04425725, df = 390-12)
conf_int(-0.1059000
, 0.04425725, df = 390-15)
# Result matrix
results.casetiming = matrix(NA, nrow = 2, ncol = 3)
colnames(results.casetiming) = c("estimate", "std.error", "p.val")
# Parameters
model.poss = c("within", "random")
response = "casegrowth"
frequency = "weekly"
type.effect = "total"
infovar = FALSE
# Allocation
j = 1
for (model in model.poss) {
# Store formula
formula = construct.formula(response = response, frequency = frequency, model = model, infovar = infovar, type.effect = type.effect)
# Store data; change configuration of data processing here to examine lag, shift and r.infovar
data = data.prep(lag = 7, shift = 21, response = response, r.infovar = 21, frequency = frequency)$data
# Fixed effects model
fit = plm(formula,
data = data, model = model,
index = c("X.Canton_3", "X.oneweek"),
effect = "twoways")
if (model == "within") {
# Covariance matrix
res = coeftest(fit, vcov = function(x)
clubSandwich::vcovCR(x, type = "CR0", cluster = c(data$X.oneweek, data$X.Canton_3)))
# Results
results.casetiming[j,1] = res["W",1]
results.casetiming[j,2] = res["W",2]
results.casetiming[j,3] = res["W",4]
} else {
# Covariance matrix
res = coeftest(fit, vcov = function(x)
sandwich::vcovHC(x, type = "HC3"))
# Results
results.casetiming[j,1] = res["W",1]
results.casetiming[j,2] = res["W",2]
results.casetiming[j,3] = res["W",4]
}
j = j + 1
}
# Naming
results.casetiming = as.data.frame(results.casetiming, row.names = c("Case-Infovar 21 FE Casegrowth", "Case-Infovar 21 RE Casegrowth"))
View(results.casetiming)
conf_int(-0.13570826
, 0.12030680, df = 390-15)
conf_int(0.02356038
, 0.09954992, df = 390-15)
# Do the timing for the de-biased fixed effects approach
multiple_split_timing = function(response, frequency, infovar, type.effect) {
# response: response variable in {median_R_mean, casegrowth}
# frequency: frequency in {daily, weekly}
# infovar: add additional information variables
# type.effect: direct or total to include behavior variables or not
# Output: bias.corrected estimate of mask policy
# Data
data = data.prep.halfcantons(response = response, r.infovar = 14, shift = 21)$data
# Store formula
formula = construct.formula(response = response, frequency = frequency, model = "within", infovar = infovar, type.effect = type.effect)
# Number of splits along the cross-section
s = 20
# Fit non-debiased model daily or weekly and save time and unit for sampling later
if (frequency == "daily") {
uc     = plm(formula, data = data, model = "within", index = c("X.Canton_3", "X.day"), effect = "twoways")
time   = as.double(data$X.day)
unit   = as.double(data$X.Canton_3)
} else {
uc     = plm(formula, data = data, model = "within", index = c("X.Canton_3", "X.oneweek"), effect = "twoways")
time   = as.double(data$X.oneweek)
unit   = as.double(data$X.Canton_3)
}
# Start computation
across = 0 * coef(uc)
for (k in 1:s) {
# Sampling process
sample1 = sample(unique(unit), ceiling(length(unique(unit))/2), replace = FALSE)
subsample1 = ((unit %in% sample1) & (time <= median(time))) |
((!(unit %in% sample1)) & (time > median(time)))
subsample2 = ((unit %in% sample1) & (time > median(time))) |
((!(unit %in% sample1)) & (time <= median(time)))
if (frequency == "daily") {
cross1 = plm(formula, data = data[subsample1,], model = "within",
index = c("X.Canton_3", "X.day"), effect = "twoways")
cross2 = plm(formula, data = data[subsample2,], model = "within",
index = c("X.Canton_3", "X.day"),effect = "twoways")
} else {
cross1 = plm(formula, data = data[subsample1,], model = "within",
index = c("X.Canton_3", "X.oneweek"), effect = "twoways")
cross2 = plm(formula, data = data[subsample2,], model = "within",
index = c("X.Canton_3", "X.oneweek"),effect = "twoways")
}
across = across + ((coef(cross1) + coef(cross2))/2)/s
}
# Average cross over corrected
acbc = 2 * coef(uc) - across
return(acbc)
}
multiple_split_timing(response = "casegrowth", frequency = "weekly", infovar = FALSE, type.effect = "total")
multiple_split_timing(response = "median_R_mean", frequency = "weekly", infovar = FALSE, type.effect = "total")
View(results.rinfovar)
conf_int(-0.2303214701, 0.05362931, 390-12)
View(results.casetiming)
conf_int(-0.309426230, 0.12030680, 390-12)
View(results.month)
conf_int(-0.162902657959934, 0.05042567, 390-12)
conf_int(-0.162902657959934, 0.04841745, 390-12)
View(results.month)
conf_int(-0.255097887651927, 0.14625967, 390-12)
conf_int(-0.255097887651927, 0.13974752, 390-12)
# (6) Remove observations according to the cooks distance rule of thumb being CD > 4/n. We also report the change in R^2
# induced via the removal of these observations. This only works for the fixed effects approach. We again use the direct effect due
# to there being no difference when comparing to the total effect. We use the canton-time standard errors. Note that the degrees of freedom
# are not correct yet.
# Result matrix
results.cooks = matrix(NA, nrow = 2, ncol = 7)
colnames(results.cooks) = c("estimate", "std.error", "p.val", "r.squared", "deleted", "diff.point", "diff.rsquared")
# Parameters
resp.poss = c("casegrowth", "median_R_mean")
model = "within"
frequency = "weekly"
type.effect = "total"
infovar = FALSE
# Allocation
j = 1
for (response in resp.poss) {
# Two-way demean data to use in linear model (lm)
data = tw.demean(data = data.prep(lag = 7, shift = 14, response = response, r.infovar = 21, frequency = frequency)$data,
response = response, frequency = frequency)
# Store formula
formula = construct.formula(response = response, frequency = frequency, model = model, infovar = infovar, type.effect = type.effect)
# Run fixed effects regression via lm
fit.original = lm(formula, data = data)
# Save orginal R^2
r.squared.original = r.sq(fit = fit.original, frequency = frequency, response = response)
# Compute cooks distance and determine influential observations
cooksD = cooks.distance(fit.original)
influential = cooksD[(cooksD > 4/nrow(data))]
influential.05 = cooksD[(cooksD > 0.5)]
# Remove outlaying observations
names_of_influential = names(influential)
outliers = data[names_of_influential,]
data_without_outliers = data %>%
anti_join(outliers)
# Run fixed effects regression via lm on reduced data
fit.reduced = lm(formula, data = data_without_outliers)
# Covariance matrix
res = coeftest(fit.reduced, vcov = function(x)
sandwich::vcovCL(x, cluster = ~ X.oneweek + X.Canton_3))
# Save new R^2
r.squared.reduced = r.sq(fit = fit.reduced, frequency = frequency, response = response)
# Results
results.cooks[j,1] = res["W",1]
results.cooks[j,2] = res["W",2]
results.cooks[j,3] = res["W",4]
results.cooks[j,4] = r.squared.reduced
results.cooks[j,5] = length(influential)
results.cooks[j,6] = summary(fit.reduced)$coefficients["W",1] - summary(fit.original)$coefficients["W",1]
results.cooks[j,7] = r.squared.reduced - r.squared.original
j = j + 1
}
# Naming
results.cooks = as.data.frame(results.cooks, row.names = c("CooksD FE Casegrowth", "CooksD FE R"))
View(results.cooks)
conf_int(-0.08042804, 0.01112076, 382-12)
conf_int(-0.21259003, 0.09495722, 390-14-12)
conf_int(-0.115339456774267, 0.0418770680024007, 24*26-12)
conf_int(-0.125339066893885, 0.0418770680024007, 24*26-12)
conf_int(-0.198879227096485, 0.0504253174182802, 24*26-12)
conf_int(-0.252819325055186, 0.0995772066353582, 24*26-12)
conf_int(-0.277991936431424, 0.0995772066353582, 24*26-12)
conf_int(-0.383782482023541, 0.0987265093455925, 24*26-12)
conf_int(-0.26707910151375, 0.204913152507144, 24*26-12)
conf_int(-0.340263923555322, 0.242675729116385, 24*26-12)
conf_int(-0.919763719414602, 0.756991429894835, 24*26-12)
# (I) OVERVIEW
# This script runs all the proposed models using the helper function that are sourced
# from helperfunctions.R. Finally, the results are compiled such that they can be further
# called to create tables and plots.
################################################################################
# (II) ENVIRONMENT AND PACKAGES
# Empty environment
rm(list = ls())
# Reproducibility (bootstrap and more)
set.seed(42)
# Set working directory to the root node of folder structure
#setwd(".\\Mask_Project\\Final")
setwd("C:/Users/eminu/OneDrive/Desktop/Facial-Mask-Policy-COVID-19")
# Read helper functions. Note that they are in the same directory. Add the corresponding path
# otherwise.
#source(".\\Scripts\\helperfunctions.R")
source("./Code/helperfunctions.R")
################################################################################
# (III) ESTIMATION
# We will generate all models of interest. We start with the 2^3 models that we run
# through the estimation.R function, which are the fixed effects and random effects models. For case-growth,
# we further look at the results when including the additional information variables.
# We then run the 2^2 models that we run through the
# multiple_split.R function, which are the de-biased fixed effects models. Lastly, we estimate
# the 2^3 models using the double machine learning framework. We keep frequency in the loop for easy
# access to the results of the daily models if wanted.
# Start with the fixed effects and random effects models
freq.poss = c("weekly")
response.poss = c("median_R_mean", "casegrowth")
model.poss = c("within", "random")
#model.poss = c("within")
type.effect.poss = c("direct", "total")
# Allocation of results
results.list.fe = vector("list", 8)
i = 1
# Run the models
for (frequency in freq.poss) {
for (response in response.poss) {
for (model in model.poss) {
for (type.effect in type.effect.poss) {
results.list.fe[[i]] = list(results = estimation(frequency = frequency, response = response, model = model, infovar = TRUE, type.effect = type.effect),
frequency = frequency,
response = response,
model = model,
type.effect = type.effect)
i = i+1
}
}
}
}
View(results.list.fe)
results.list.fe[[1]][["results"]][["fit"]][["coefficients"]]
results.list.fe[[1]][["results"]][["fit"]]
summary(results.list.fe[[1]][["results"]][["fit"]])
conf_int(-0.12601238, 0.12353525, 339)
conf_int(-0.12601238, 0.12353525, df = 339)
conf_int = function(point_est, sd, df) {
return(round(c(point_est, point_est - qt(0.975, df)*sd, point_est + qt(0.975, df)*sd),2))
}
conf_int(-0.12601238, 0.12353525, df = 339)
summary(results.list.fe[[2]][["results"]][["fit"]])
summary(results.list.fe[[3]][["results"]][["fit"]])
conf_int(-9.9329e-02, 1.0722e-01, df = 339)
# Run the models
for (frequency in freq.poss) {
for (response in response.poss) {
for(type.effect in type.effect.poss) {
results.list.dfe[[i]] = list(multiple_split(response = response, frequency = frequency, infovar = TRUE, type.effect = type.effect),
frequency = frequency,
response = response,
model = "debiased",
type.effect = type.effect)
i = i+1
}
}
}
# Run the de-biased models via multiple sample splitting
results.list.dfe = vector("list", 4)
i = 1
# Run the models
for (frequency in freq.poss) {
for (response in response.poss) {
for(type.effect in type.effect.poss) {
results.list.dfe[[i]] = list(multiple_split(response = response, frequency = frequency, infovar = TRUE, type.effect = type.effect),
frequency = frequency,
response = response,
model = "debiased",
type.effect = type.effect)
i = i+1
}
}
}
View(results.list.dfe)
conf_int(-0.16666, 0.12353525, df = 339)
conf_int(-0.340263923555322,0.242675729116385, df = 339)
conf_int(-0.808157615975919,0.658871638784253, df = 339)
View(results.list.fe)
# Start with the fixed effects and random effects models
freq.poss = c("weekly")
response.poss = c("median_R_mean", "casegrowth")
model.poss = c("within", "random")
#model.poss = c("within")
type.effect.poss = c("direct", "total")
# Allocation of results
results.list.fe = vector("list", 8)
i = 1
# Run the models
for (frequency in freq.poss) {
for (response in response.poss) {
for (model in model.poss) {
for (type.effect in type.effect.poss) {
results.list.fe[[i]] = list(results = estimation(frequency = frequency, response = response, model = model, infovar = TRUE, type.effect = type.effect),
frequency = frequency,
response = response,
model = model,
type.effect = type.effect)
i = i+1
}
}
}
}
View(results.list.fe)
conf_int(-0.919763719414602,0.756991429894835, df = 339)
26/47
